# ğŸŒ Ollama + Google Maps AI Finder

A modern full-stack application that combines **local LLM (Ollama)** and **Google Maps Places API** to help users find places (restaurants, cafÃ©s, etc.) using natural language.

The interface uses a **dark, modern Chat-AI style**, built with **React + Vite + Tailwind CSS**, and the backend is powered by **Flask (Python)** with rate-limiting, caching, and secure API communication.

---

## ğŸš€ Features

- ğŸ” **AI-enhanced searching** (Ollama refines user query)
- ğŸ“ **Google Maps Text Search integration**
- ğŸ—ºï¸ **Live embedded map preview**
- ğŸš— **Open Google Maps directions**
- ğŸŒ™ **Dark AI-chat themed UI**
- âš¡ Fast thanks to Vite + Tailwind CSS
- ğŸ” Secure backend with:
  - Flask rate limiter
  - Environment variable secrets
  - CORS protection
  - API key masking
  - Request caching

---

## ğŸ—ï¸ Tech Stack

### **Frontend**
- React (JavaScript)
- Vite
- Tailwind CSS
- Modern Dark UI

### **Backend**
- Python Flask
- httpx
- Flask-Limiter
- Flask-Caching
- Dotenv

### **AI**
- Local LLM using **Ollama**  
  (Recommended models: `llama3`, `llama3.1`, `mistral`, etc.)

### **Maps**
- Google Maps Places API  
- Google Maps Embed API

---

## ğŸ“ Project Structure

```php
maps-ollama-projects/
â”‚
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ app.py
â”‚ â”œâ”€â”€ requirements.txt
â”‚ â”œâ”€â”€ .env
â”‚ â””â”€â”€ .venv/
â”‚
â””â”€â”€ frontend/
â”œâ”€â”€ index.html
â”œâ”€â”€ postcss.config.js
â”œâ”€â”€ tailwind.config.js
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ App.js
â”‚ â”œâ”€â”€ main.js
â”‚ â”œâ”€â”€ SearchForm.js
â”‚ â””â”€â”€ MapEmbed.js
â””â”€â”€ package.json
```

---

# ğŸ”§ 1. Backend Setup (Flask)

## ğŸ“Œ Install dependencies

```php
cd backend
python -m venv .venv
.\.venv\Scripts\activate    # Windows
pip install -r requirements.txt
```

## ğŸ“Œ Create .env file
```php
GOOGLE_MAPS_API_KEY=YOUR_GOOGLE_CLOUD_API_KEY
PORT=5000
OLLAMA_URL=http://localhost:11434/api/generate
```
âœ” Make sure Places API is enabled
âœ” Restrict key using IP (127.0.0.1 or your local network IP)

## ğŸ“Œ Run backend
```php
python app.py
```
Backend available at:
```php
http://localhost:5000
```

# ğŸ¨ 2. Frontend Setup (React + Vite + Tailwind)
```php
cd frontend
npm install
npm run dev
```

Frontend available at:
```php
http://localhost:5173
```

# â–¶ï¸ 3. Running the Application

Start Ollama:
```php
ollama serve
```

Start backend:
```php
cd backend
.\.venv\Scripts\activate
python app.py
```

Start frontend:
```php
cd frontend
npm run dev
```

Open browser:
```php
http://localhost:5173
```

# ğŸ§ª Example Query

Try searching:
```php
"24h cafÃ© in Depok"
"best sushi near Surabaya"
"romantic dinner place in Jakarta"
"cheap coffee shop near UI"
```

Ollama will refine the query â†’ backend sends to Google â†’ results display with map.